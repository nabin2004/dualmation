# ğŸ¬ DualAnimate

> **Hybrid LLM-Diffusion Framework for Educational Animation Generation with RL Feedback**

DualAnimate combines the mathematical precision of LLM-generated [Manim](https://www.manim.community/) code with the visual richness of diffusion-generated backgrounds, unified by self-supervised multimodal embeddings and reinforced through multi-component reward scoring.

---

## ğŸ—ï¸ Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Concept Description â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Multimodal Embedding â”‚
                    â”‚ CodeBERT + ViT (SSL) â”‚
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                         â–¼           â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ ğŸ§  Brain 1   â”‚ â”‚ ğŸ¨ Brain 2   â”‚
              â”‚ LLM Code Gen â”‚ â”‚ Diffusion Genâ”‚
              â”‚ (Manim Code) â”‚ â”‚ (Background) â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼                â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  âŠ• Alpha Compositor       â”‚
              â”‚  Foreground + Background  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  ğŸ¯ RL Reward Model       â”‚
              â”‚  Alignment Â· Quality Â·    â”‚
              â”‚  Compilation Success      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  ğŸ¬ Educational Animation â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†‘ RL Feedback Loop â†‘
```

---

## ğŸ“¦ Project Structure

```
dualmation/
â”œâ”€â”€ src/dualmation/
â”‚   â”œâ”€â”€ embeddings/        # CodeBERT + ViT + InfoNCE contrastive
â”‚   â”œâ”€â”€ llm/               # LLM â†’ Manim code generation
â”‚   â”œâ”€â”€ diffusion/         # Diffusion â†’ visual backgrounds
â”‚   â”œâ”€â”€ compositor/        # Alpha compositing engine
â”‚   â”œâ”€â”€ reward/            # Multi-component RL reward model
â”‚   â””â”€â”€ pipeline.py        # End-to-end orchestrator
â”œâ”€â”€ tests/                 # pytest test suite
â”œâ”€â”€ manim_scripts/         # Example Manim scenes
â”œâ”€â”€ notebooks/             # Jupyter notebooks
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ outputs/               # Generated samples
â””â”€â”€ pyproject.toml
```

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/nabin2004/dualmation.git
cd dualmation

# Create virtual environment
python -m venv .venv
source .venv/bin/activate

# Install in development mode
pip install -e ".[dev]"
```

### Usage

```python
from dualmation.pipeline import DualAnimatePipeline, PipelineConfig

config = PipelineConfig(
    concept="Explain gradient descent visually",
    llm_model="codellama/CodeLlama-7b-hf",
    diffusion_model="stabilityai/stable-diffusion-2-1",
)

pipeline = DualAnimatePipeline(config)
result = pipeline.run()
```

---

## ğŸ§© Modules

| Module | Description |
|--------|-------------|
| `embeddings` | Self-supervised multimodal embedding space (CodeBERT + ViT, InfoNCE loss) |
| `llm` | LLM-driven Manim Python code generation |
| `diffusion` | Diffusion-based visual context and background generation |
| `compositor` | Alpha compositing of Manim foreground + diffusion background |
| `reward` | Multi-component RL reward: concept alignment, visual quality, compilation success |
| `pipeline` | End-to-end orchestrator connecting all modules |

---

## ğŸ§ª Testing

```bash
python -m pytest tests/ -v
```

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

## ğŸ—ºï¸ Roadmap

- [x] Project structure & dependencies
- [ ] Self-supervised multimodal embeddings
- [ ] LLM code generation module
- [ ] Diffusion visual generation module
- [ ] Alpha compositor
- [ ] RL reward model
- [ ] End-to-end pipeline
- [ ] Example notebooks & sample outputs

---

*Built with â¤ï¸ using PyTorch, HuggingFace Transformers, Diffusers, and Manim.*
