"""
End-to-end DualAnimate pipeline orchestrator.

Connects all modules: embeddings â†’ LLM code gen â†’ diffusion visual gen â†’
compositor â†’ reward scoring. Uses ExperimentConfig from configs/ for
reproducible, configurable experiments.
"""

from __future__ import annotations

import logging
from dataclasses import dataclass, field
from pathlib import Path

import torch
from PIL import Image

from dualmation.compositor.compositor import AlphaCompositor, CompositeConfig
from dualmation.experiment.config import ExperimentConfig, load_config
from dualmation.experiment.reproducibility import set_seed, save_environment_snapshot
from dualmation.experiment.logging_setup import setup_logging
from dualmation.experiment.tracker import ExperimentTracker, TrackerConfig
from dualmation.reward.reward_model import RewardConfig, RewardModel, RewardScore

logger = logging.getLogger(__name__)


@dataclass
class PipelineResult:
    """Result from a single pipeline run.

    Attributes:
        concept: The input concept.
        generated_code: The Manim Python code generated by the LLM.
        background_images: Diffusion-generated background images.
        composited_frames: Final composited output frames.
        reward: Reward score from the RL scorer.
        concept_embedding: The concept's embedding in the shared space.
    """

    concept: str
    generated_code: str = ""
    generated_scenes: list[dict[str, str]] = field(default_factory=list) # List of {"description": ..., "code": ...}
    background_images: list[Image.Image] = field(default_factory=list)
    composited_frames: list[Image.Image] = field(default_factory=list)
    reward: RewardScore | None = None
    concept_embedding: torch.Tensor | None = None


class DualAnimatePipeline:
    """Full DualAnimate inference pipeline.

    Orchestrates the flow:
    1. Encode concept â†’ multimodal embedding
    2. LLM generates Manim code (Brain 1: Logic)
    3. Diffusion generates visual background (Brain 2: Aesthetics)
    4. Alpha compositor merges foreground + background
    5. Reward model scores the output
    6. (Training mode) RL feedback updates LLM and diffusion

    The pipeline reads its configuration from ExperimentConfig (YAML files
    in configs/) and integrates with the experiment tracking framework.

    Args:
        config: ExperimentConfig loaded from YAML or constructed programmatically.
    """

    def __init__(self, config: ExperimentConfig) -> None:
        self.config = config
        self.device = self._resolve_device(config.device)

        # Set seed for reproducibility
        set_seed(config.seed)

        # Build sub-configs from ExperimentConfig
        composite_cfg = CompositeConfig(
            output_width=config.compositor.output_width,
            output_height=config.compositor.output_height,
            blend_mode=config.compositor.blend_mode,
            background_opacity=config.compositor.background_opacity,
            foreground_opacity=config.compositor.foreground_opacity,
        )
        reward_cfg = RewardConfig(
            weight_alignment=config.reward.weight_alignment,
            weight_visual=config.reward.weight_visual,
            weight_compilation=config.reward.weight_compilation,
        )

        # Modules are lazy-loaded to avoid loading everything at init
        self._code_encoder = None
        self._visual_encoder = None
        self._code_generator = None
        self._visual_generator = None
        self._compositor = AlphaCompositor(composite_cfg)
        self._reward_model = RewardModel(reward_cfg, device=self.device)

        # Experiment tracker (optional)
        self._tracker: ExperimentTracker | None = None

    @staticmethod
    def _resolve_device(device: str) -> str:
        """Resolve 'auto' device to actual device string."""
        if device == "auto":
            return "cuda" if torch.cuda.is_available() else "cpu"
        return device

    @classmethod
    def from_config_file(cls, config_path: str | Path, overrides: dict | None = None) -> DualAnimatePipeline:
        """Create a pipeline from a YAML config file.

        Args:
            config_path: Path to YAML config file (e.g., configs/default.yaml).
            overrides: Optional dict of overrides (supports dot notation).

        Returns:
            Configured DualAnimatePipeline instance.
        """
        config = load_config(config_path, overrides=overrides)
        return cls(config)

    def attach_tracker(self, tracker: ExperimentTracker) -> None:
        """Attach an experiment tracker for logging metrics during runs."""
        self._tracker = tracker

    # â”€â”€ Lazy-loaded modules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @property
    def code_encoder(self):
        """Lazy-load the code encoder."""
        if self._code_encoder is None:
            from dualmation.embeddings.code_encoder import CodeEncoder

            self._code_encoder = CodeEncoder(
                model_name=self.config.embedding.code_model,
                embedding_dim=self.config.embedding.embedding_dim,
            ).to(self.device)
        return self._code_encoder

    @property
    def visual_encoder(self):
        """Lazy-load the visual encoder."""
        if self._visual_encoder is None:
            from dualmation.embeddings.visual_encoder import VisualEncoder

            self._visual_encoder = VisualEncoder(
                model_name=self.config.embedding.visual_model,
                embedding_dim=self.config.embedding.embedding_dim,
            ).to(self.device)
        return self._visual_encoder

    @property
    def code_generator(self):
        """Lazy-load the LLM code generator."""
        if self._code_generator is None:
            from dualmation.llm.code_generator import ManimCodeGenerator

            self._code_generator = ManimCodeGenerator(
                model_name=self.config.llm.model_name,
                device=self.device,
            )
        return self._code_generator

    @property
    def visual_generator(self):
        """Lazy-load the diffusion visual generator."""
        if self._visual_generator is None:
            from dualmation.diffusion.visual_generator import VisualGenerator

            self._visual_generator = VisualGenerator(
                model_name=self.config.diffusion.model_name,
                device=self.device,
            )
        return self._visual_generator

    # â”€â”€ Pipeline execution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def run(self, concept: str | None = None) -> PipelineResult:
        """Execute the full pipeline for a concept.

        Args:
            concept: Override concept from config if provided.

        Returns:
            PipelineResult with all generated artifacts and scores.
        """
        concept = concept or self.config.experiment_name
        result = PipelineResult(concept=concept)

        logger.info("ðŸš€ Pipeline starting for concept: %s", concept)
        logger.info("ðŸ“‹ Config: seed=%d, device=%s", self.config.seed, self.device)

        # Step 1: Generate concept embedding (optional)
        embedding = None
        try:
            embedding = self.code_encoder.encode(concept)
            result.concept_embedding = embedding
            logger.info("âœ… Concept embedding generated: shape=%s", embedding.shape)
            if self._tracker:
                self._tracker.log_scalar("pipeline/embedding_norm", embedding.norm().item())
        except Exception as e:
            logger.warning("âš ï¸ Embedding generation failed, continuing without: %s", e)

        # Step 2: LLM â†’ Manim code (Brain 1: Logic)
        if self.config.llm.enable_multi_scene:
            logger.info("åˆ† Multi-scene mode enabled. Decomposing concept...")
            try:
                scene_descriptions = self.code_generator.decompose_concept(
                    concept, max_scenes=self.config.llm.max_scenes
                )
                logger.info("Found %d chapters: %s", len(scene_descriptions), scene_descriptions)
                
                previous_context = ""
                for i, desc in enumerate(scene_descriptions):
                    logger.info("ðŸŽ¬ Generating Chapter %d/%d: %s", i+1, len(scene_descriptions), desc)
                    code = self.code_generator.generate_scene_with_context(
                        concept=concept,
                        scene_description=desc,
                        scene_index=i,
                        total_scenes=len(scene_descriptions),
                        previous_context=previous_context
                    )
                    result.generated_scenes.append({"description": desc, "code": code})
                    # Use current code as context for next turn (simplified)
                    previous_context += f"\nChapter {i+1} code summary:\n{code[:500]}..."
                
                # Combine codes for the final output or take the first/last? 
                # For now, let's join them with comments
                result.generated_code = "\n\n# " + "="*40 + "\n# MULTI-SCENE ANIMATION\n# " + "="*40 + "\n\n"
                for i, s in enumerate(result.generated_scenes):
                    result.generated_code += f"\n\n# CHAPTER {i+1}: {s['description']}\n{s['code']}\n"
                
            except Exception as e:
                logger.error("âŒ Multi-scene generation failed: %s", e)
                result.generated_code = "" # Ensure it's empty to skip later steps
        else:
            try:
                code = self.code_generator.generate_with_embedding(
                    concept=concept, embedding=embedding
                )
                result.generated_code = code
                logger.info("âœ… Manim code generated: %d chars", len(code))
            except Exception as e:
                logger.error("âŒ Code generation failed: %s", e)
                result.generated_code = ""

        # Early exit if we have no code to work with
        if not result.generated_code:
            logger.warning("âš ï¸ No code generated, skipping visual gen and reward scoring.")
            self._save_outputs(result)
            return result

        # Step 3: Diffusion â†’ visual background (Brain 2: Aesthetics)
        try:
            backgrounds = self.visual_generator.generate_with_embedding(
                concept=concept, embedding=embedding
            )
            result.background_images = backgrounds
            logger.info("âœ… Background generated: %d images", len(backgrounds))
            if self._tracker and backgrounds:
                self._tracker.log_image("pipeline/background", backgrounds[0])
        except Exception as e:
            logger.warning("âš ï¸ Background generation failed: %s", e)

        # Step 4: Iterative Self-Correction (if enabled)
        max_turns = self.config.llm.max_correction_turns if self.config.llm.enable_self_correction else 0
        current_turn = 0
        
        while True:
            # Step 5: Reward scoring
            try:
                visual = result.background_images[0] if result.background_images else None
                reward = self._reward_model.score(
                    code=result.generated_code,
                    visual=visual,
                    concept=concept,
                    concept_embedding=embedding,
                )
                result.reward = reward
                
                # Check for success or if we should retry
                if reward.compilation_success >= 1.0 or current_turn >= max_turns:
                    if reward.compilation_success >= 1.0:
                        logger.info("âœ… Reward: total=%.3f (compilation success on turn %d)", reward.total, current_turn)
                    else:
                        logger.warning("âš ï¸ Max correction turns reached (%d). Final score: %.3f", max_turns, reward.total)
                    break
                
                # Retry: generate correction
                current_turn += 1
                logger.info("ðŸ”„ Self-correction turn %d: fixing code based on error...", current_turn)
                logger.debug("Error: %s", reward.compilation_output)
                
                result.generated_code = self.code_generator.generate_correction(
                    concept=concept,
                    original_code=result.generated_code,
                    error_message=reward.compilation_output,
                )
                
            except Exception as e:
                logger.warning("âš ï¸ Reward scoring/correction failed: %s", e)
                break

        if self._tracker:
            self._tracker.log_scalar("pipeline/code_length", len(result.generated_code))
            self._tracker.log_text("pipeline/generated_code", result.generated_code)
            if result.reward:
                self._tracker.log_scalars("reward", {
                    "total": result.reward.total,
                    "alignment": result.reward.concept_alignment,
                    "visual_quality": result.reward.visual_quality,
                    "compilation": result.reward.compilation_success,
                })

        # Save outputs
        self._save_outputs(result)

        logger.info("ðŸŽ¬ Pipeline complete for: %s", concept)
        return result

    def _save_outputs(self, result: PipelineResult) -> None:
        """Save all generated artifacts to the output directory."""
        output_dir = Path(self.config.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        # Save generated code
        code_path = output_dir / "generated_scene.py"
        code_path.write_text(result.generated_code)
        logger.info("Saved code: %s", code_path)

        # Save background images
        for i, img in enumerate(result.background_images):
            img_path = output_dir / f"background_{i:04d}.png"
            img.save(img_path)

        # Save composited frames
        for i, frame in enumerate(result.composited_frames):
            frame_path = output_dir / f"composited_{i:04d}.png"
            frame.convert("RGB").save(frame_path)

        # Save reward summary
        if result.reward:
            reward_path = output_dir / "reward_summary.txt"
            reward_path.write_text(
                f"Concept: {result.concept}\n"
                f"Total Reward: {result.reward.total:.4f}\n"
                f"Concept Alignment: {result.reward.concept_alignment:.4f}\n"
                f"Visual Quality: {result.reward.visual_quality:.4f}\n"
                f"Compilation Success: {result.reward.compilation_success:.4f}\n"
                f"Compilation Output: {result.reward.compilation_output}\n"
            )
